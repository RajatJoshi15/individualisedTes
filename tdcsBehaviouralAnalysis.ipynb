{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import shapiro\n",
    "import scipy.stats as stats\n",
    "import pingouin as pg\n",
    "import statistics\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \" \" #path to folder containing logfiles for every tDCS conditon\n",
    "filepaths = os.listdir(filepath)\n",
    "order = [1, 2, 0]\n",
    "filepaths = [filepaths[i] for i in order ]\n",
    "# outliers = []\n",
    "outliers = ['SUBC3FP2010', 'SUBC3FP2054']\n",
    "blocks = ['Block'+str(i+1) for i in range(8)]\n",
    "block_mean = pd.DataFrame(index = blocks)\n",
    "block_norm_cent_mean = pd.DataFrame(index = blocks)\n",
    "block_rt_abs_mean = pd.DataFrame(index = blocks)\n",
    "block_std = pd.DataFrame(index = blocks)\n",
    "block_rt_abs_std = pd.DataFrame(index = blocks)\n",
    "block_rt_abs_er = pd.DataFrame(index = blocks)\n",
    "block_err = pd.DataFrame(index = blocks)\n",
    "block_norm_cent_err = pd.DataFrame(index = blocks)\n",
    "data_files_full = dict()\n",
    "variability_sub_all_blocks = dict()\n",
    "data_files = dict()\n",
    "data_file_cent = dict()\n",
    "upper_bound = dict()\n",
    "lower_bound = dict()\n",
    "error_dict_full = dict()\n",
    "error_dict_block = dict()\n",
    "block_er_mean = pd.DataFrame(index = blocks)\n",
    "block_er_mean_norm = pd.DataFrame(index = blocks)\n",
    "block_er_sem = pd.DataFrame(index = blocks)\n",
    "block_er_sem_norm = pd.DataFrame(index = blocks)\n",
    "anova_file_full = []\n",
    "final_VAR_file = dict()\n",
    "an_learn = []\n",
    "an_learn_cond=[]\n",
    "an_learn_sub = []\n",
    "an_learn_nn = []\n",
    "data_files_abs = dict()\n",
    "learn_dict = dict()\n",
    "learn_full = []\n",
    "learn_df = pd.DataFrame()\n",
    "data_files_absRT = dict()\n",
    "data_file_absRT_sub  = dict()\n",
    "total_correct_df = pd.DataFrame()\n",
    "timeDuration_df = pd.DataFrame()\n",
    "\n",
    "for file in filepaths:   \n",
    "    files = os.listdir(filepath + file +'/')\n",
    "    files_except_outliers = [i for i in files if i[:11] not in outliers]\n",
    "    final = pd.DataFrame(index = blocks)\n",
    "    final_cent = pd.DataFrame(index = blocks)\n",
    "    final_er_norm = pd.DataFrame(index = blocks)\n",
    "    final_er = pd.DataFrame(index = blocks)\n",
    "    final_er_full = pd.DataFrame(index = ['all'])\n",
    "    final_abs = pd.DataFrame(index = blocks)\n",
    "    final_var = pd.DataFrame(index = blocks)\n",
    "    total_correct = []\n",
    "    timeDuration = []\n",
    "\n",
    "    for indexx,i in enumerate(files_except_outliers):\n",
    "        anova_file = pd.DataFrame()\n",
    "        filename = i[:13]\n",
    "        if filename[-1] == '1':\n",
    "            skip_r = 2957\n",
    "        else: skip_r = 2896\n",
    "\n",
    "        df = pd.read_csv(filepath + file +'/' + i, skiprows=skip_r, delimiter = \"\\t\")\n",
    "        df1 = df[df[\"Code\"].str.len()>5] #to seperate nan and isi from block\n",
    "\n",
    "        df1[[\"Block\", \"Condition\", \"Target Button\", \"Trial Number\"]] = df1[\"Code\"].str.split(';',expand=True)\n",
    "        df1.drop(\"Code\", axis=1, inplace = True) \n",
    "        cols = [\"Block\", \"Condition\", \"Target Button\", \"Trial Number\"]\n",
    "\n",
    "        for col in reversed(cols):\n",
    "            temp = df1[col].str.strip()\n",
    "            df1.drop(labels=[col], axis=1, inplace= True)\n",
    "            df1.insert(1, col, temp)\n",
    "\n",
    "        cols.remove(\"Condition\")\n",
    "        df1 = df1[df1['Block'] != 'PRACTICE BLOCK'] #removing practice blocks \n",
    "        for col in cols:\n",
    "            df1[col] = df1[col].str.extract('(\\d+)').astype(int) #extract numbers from string \n",
    "        df1[\"RT\"] = df1[\"RT\"]/10 \n",
    "        ## nitshe paper, 2003, removing trials\n",
    "        incorrect = df1[df1[\"Type\"]==\"incorrect\"]\n",
    "        hit = df1[df1[\"Type\"]==\"hit\"]\n",
    "        blockwise_before_drop = hit.groupby(\"Block\").size().reset_index()\n",
    "        blockwise_before_drop.drop('Block', axis=1, inplace = True)\n",
    "        final_er['er_'+filename] = 1 - (blockwise_before_drop.to_numpy() / 120)\n",
    "        final_er_full['er_'+filename] = 1-(len(hit) / len(df1))\n",
    "        total_correct.append(len(hit))\n",
    "        time = hit[\"Time\"].tolist()\n",
    "        timeDuration.append(time[-1]/60/10000)\n",
    "\n",
    "        RT_mean = hit[\"RT\"].mean()\n",
    "        RT_std = hit[\"RT\"].std()\n",
    "        hit.drop(hit[(hit[\"RT\"]> (RT_mean + 3*RT_std))].index, inplace=True)\n",
    "        blockwise = hit.groupby(\"Block\")[\"RT\"].mean().reset_index()\n",
    "        size = hit.groupby(\"Block\").size().reset_index()\n",
    "        blockwise['normal'] = blockwise['RT']/blockwise.iloc[0]['RT']\n",
    "        final['norm_'+filename] = blockwise['normal'].to_numpy()\n",
    "\n",
    "            ## PLOTTING INDIVIDUAL performance across the three conditions        \n",
    "        # plt.figure(indexx)\n",
    "        # plt.plot(blockwise[\"normal\"],label = file)\n",
    "        # plt.legend()\n",
    "        # plt.ylabel('RT')\n",
    "        # plt.title(filename)\n",
    "        # plt.savefig(\"E:\\\\rajat\\python_plots\\ind_files\\\\ \"+ filename + \".jpg\")\n",
    "        \n",
    "        #implicit learning i.e., Block 6-Block5\n",
    "        learn = blockwise.iloc[5]['normal'] - blockwise.iloc[4]['normal']  ## change for block\n",
    "        learn_nn = blockwise.iloc[7]['RT'] - blockwise.iloc[2]['RT']\n",
    "        norm_cent = []\n",
    "\n",
    "        #analysing percent increse across blocks\n",
    "        for index, row in blockwise.iterrows():\n",
    "            #print(blockwise.iloc[index-1]['RT'])\n",
    "            if index == 0:\n",
    "                norm_cent.append(0)\n",
    "            else:\n",
    "                # norm_cent.append((float(row[\"RT\"])-float(blockwise.iloc[index-1]['RT']))/float(row['RT']))\n",
    "                norm_cent.append((float(row[\"RT\"])-float(blockwise.iloc[index-1]['RT']))/abs(float(blockwise.iloc[index-1]['RT'])))\n",
    "\n",
    "        blockwise[\"norm_cent\"] = norm_cent\n",
    "        blockwise['var'] =  statistics.variance(blockwise['RT'])\n",
    "        blockwise['var_norm'] =  abs(blockwise['normal']-(blockwise['normal'].mean()))\n",
    "        final_var[filename] =blockwise['var'].to_numpy()\n",
    "        blockwise['ER'] = final_er.mean(axis = 1).to_numpy()\n",
    "        blockwise['ER_norm'] = blockwise['ER']/blockwise.iloc[0]['ER']\n",
    "        final_er_norm['er_norm_'+filename] = blockwise['ER_norm'].to_numpy()\n",
    "        final_abs['rt_abs_'+filename] = blockwise['RT'].to_numpy()\n",
    "        final_cent[\"RT_change\"] = blockwise[\"norm_cent\"].to_numpy()\n",
    "        an_learn.append(learn)\n",
    "        an_learn_nn.append(learn_nn)\n",
    "        an_learn_cond.append(file)\n",
    "        an_learn_sub.append(filename[-4:-2])        \n",
    "\n",
    "        learn_df[\"subject\"] =[filename[-4:-2]]\n",
    "        learn_df['learn'] = learn\n",
    "        learn_df[\"learn_nn\"] = learn_nn\n",
    "        learn_df[\"cond\"] = file\n",
    "        learn_full.append(learn_df)\n",
    "        \n",
    "        \n",
    "        anova_file['subject'] = [filename[-4:-2]]*len(blocks)\n",
    "        anova_file['rt_abs'] = blockwise['RT'].to_numpy()\n",
    "        anova_file['norm_rt'] = blockwise['normal'].to_numpy()\n",
    "        anova_file['er'] = blockwise['ER'].to_numpy()\n",
    "        anova_file['var'] = blockwise['var'].to_numpy()\n",
    "        anova_file['var_norm'] = blockwise['var_norm'].to_numpy()\n",
    "        anova_file['block'] = blocks\n",
    "        anova_file['condition'] = file\n",
    "        anova_file['norm_cent'] = blockwise[\"norm_cent\"]\n",
    "        anova_file_full.append(anova_file)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    q1 = final.quantile(.25, axis = 1)\n",
    "    q3  = final.quantile(.75, axis = 1)\n",
    "    iqr = q3-q1\n",
    "    upper_bound[file] = q3 + (1.5 * iqr)\n",
    "    lower_bound[file] = q1 - (1.5 * iqr)\n",
    "    data_files[file] = final.loc[['Block5','Block6','Block8']].T\n",
    "    data_files_absRT[file] = final_abs.loc[['Block5','Block6','Block8']].T\n",
    "    data_files_full[file] = final\n",
    "    data_file_absRT_sub[file] = final_abs\n",
    "    final_VAR_file[file] = final_var\n",
    "    data_file_cent[file] = final_cent \n",
    "    block_mean[file] = final.mean(axis=1)\n",
    "    block_norm_cent_mean[file] = final_cent.mean(axis = 1)\n",
    "    block_er_mean_norm[file] = final_er_norm.mean(axis=1)\n",
    "    block_rt_abs_mean[file] = final_abs.mean(axis=1)\n",
    "    block_std[file] = final.std(axis=1)\n",
    "    block_rt_abs_std[file] = final_abs.std(axis=1)\n",
    "    block_err[file] = final.sem(axis=1) #standard error of mean\n",
    "    block_norm_cent_err[file] =final_cent.sem(axis = 1)\n",
    "    block_er_sem_norm[file] = final_er_norm.sem(axis=1)\n",
    "    block_rt_abs_er[file] = final_abs.sem(axis=1)\n",
    "    error_dict_block[file] = final_er\n",
    "    block_er_mean[file] = final_er.mean(axis = 1)\n",
    "    block_er_sem[file] = final_er.sem(axis = 1)\n",
    "    error_dict_full[file] = final_er_full\n",
    "    data_files_abs[file] = final_abs\n",
    "    total_correct_df[file] = total_correct\n",
    "    timeDuration_df[file] = timeDuration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating csvs for ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "an_file = pd.concat(anova_file_full)\n",
    "learn_file = pd.concat(learn_full)\n",
    "anova_learn = pd.DataFrame({'Subject': an_learn_sub, 'learning':an_learn, 'learning_nn': an_learn_nn, 'condition': an_learn_cond})\n",
    "# an_file.to_csv(r\"E:/rajat/laptop_files/dissertation/SRTT_CSV/an_file_less_1mA.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cond = anova_learn.groupby('condition')['learning'].apply(list).to_dict()\n",
    "learn_cond_nn = anova_learn.groupby('condition')['learning_nn'].apply(list).to_dict()\n",
    "er_ = an_file.groupby('block')['er'].apply(list).to_dict()\n",
    "# learn_cond.set_index(\"condition\")\n",
    "anova_learn.set_index(\"Subject\",drop = \"index\", inplace = True)\n",
    "anova_learn.sort_index(inplace = True)\n",
    "# anova_learn.to_csv(r\"E:/rajat/laptop_files/dissertation/SRTT_CSV/anova_learn.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total correct trials for each tDCS condition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in total_correct_df.T.iterrows():\n",
    "    print(i + \" mean:\" + str(row.mean()))\n",
    "    print(i + \" stdDev:\" + str(row.std()))\n",
    "    print(i + \" min :\" + str(min(row)))\n",
    "    print(i + \" max :\" + str(max(row)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total stimulation time for each tDCS condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in timeDuration_df.T.iterrows():\n",
    "    print(i + \": \" + str(row.mean()))\n",
    "    print(i + \": \" + str(row.std()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Violin Plots\n",
    "RT distribution: Fixed vs Individualised dose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = data_files_full[\"Fixed dose\"]\n",
    "bb = data_files_full[\"Individualised dose\"]\n",
    "sub_list_ind = []\n",
    "for i, row in bb.T.iterrows():\n",
    "    sub_list_ind.append(i)\n",
    "\n",
    "sub_list_fix = []\n",
    "for i, row in aa.T.iterrows():\n",
    "    sub_list_fix.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lf = pd.melt(aa, value_vars=sub_list_fix, var_name = \"sub\", value_name=\"RT\")\n",
    "data_lf[\"Blocks\"] = [\"Block1\",\"Block2\", \"Block3\", \"Block4\", \"Block5\", \"Block6\", \"Block7\", \"Block8\"]*21\n",
    "data_lf[\"cond\"] = [\"Fixed\"]*len(data_lf)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lf2 = pd.melt(bb, value_vars=sub_list_ind, var_name = \"sub\", value_name=\"RT\")\n",
    "data_lf2[\"Blocks\"] = [\"Block1\",\"Block2\", \"Block3\", \"Block4\", \"Block5\", \"Block6\", \"Block7\", \"Block8\"]*21\n",
    "data_lf2[\"cond\"] = [\"Individualised\"]*len(data_lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = pd.concat([data_lf, data_lf2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_legend = [True,False,False,False, False, False,False, False]\n",
    "\n",
    "fig = go.Figure()\n",
    "for i in range(0,len(pd.unique(df_plot['Blocks']))):\n",
    "\n",
    "    fig.add_trace(go.Violin(x= df_plot['Blocks'][(df_plot['cond'] == 'Fixed') &\n",
    "                                    (df_plot['Blocks'] == pd.unique(df_plot['Blocks'])[i])],\n",
    "                        y=df_plot['RT'][(df_plot['cond'] == 'Fixed')&\n",
    "                                            (df_plot['Blocks'] == pd.unique(df_plot['Blocks'])[i])],\n",
    "                                            \n",
    "                                            legendgroup='Fixed', scalegroup='Fixed', name='Fixed',\n",
    "                        side='negative',\n",
    "                        pointpos=-1.07, # where to position points\n",
    "                        line_color='lightseagreen',\n",
    "                        showlegend=show_legend[i]\n",
    "                        ))\n",
    "            \n",
    "\n",
    "    fig.add_trace(go.Violin(x=df_plot['Blocks'][(df_plot['cond'] == 'Individualised') &\n",
    "                                    (df_plot['Blocks'] == pd.unique(df_plot['Blocks'])[i])],\n",
    "                        y=df_plot['RT'][(df_plot['cond'] == 'Individualised')&\n",
    "                                            (df_plot['Blocks'] == pd.unique(df_plot['Blocks'])[i])],\n",
    "                        legendgroup='Individualised', scalegroup='Individualised', name='Individualised',\n",
    "                        side='positive',\n",
    "                        pointpos=1.1, # where to position points\n",
    "                        line_color='mediumpurple',\n",
    "                        showlegend=show_legend[i]                        \n",
    "                        ))\n",
    "                        \n",
    "\n",
    "\n",
    "# update characteristics shared by all traces\n",
    "fig.update_traces(meanline_visible=True,\n",
    "                  points='all', # show all points\n",
    "                  jitter=0.05,  # add some jitter on points for better visibility\n",
    "                  scalemode='count') #scale violin plot area with total count\n",
    "fig.update_layout(\n",
    "    title_text=\"Behavioural Performance\",\n",
    "    # xaxis_title = \"_\",\\\n",
    "    yaxis_title = 'Normalised RT',\n",
    "    violingap=0.3, violingroupgap=0, violinmode='overlay',\n",
    "    autosize = False,\n",
    "    width = 1300, \n",
    "    height = 650,\n",
    "    font_size = 20 )\n",
    "fig.write_image(\"/home/friction_15/lab/dissertation/reviewFigures/bimodal.jpg\", scale = 10)\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysing the baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_sham_abs_gtr_1mA =data_files_abs['Sham'].iloc[0]  #sham cond baseline >1mA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_sham_abs_less_1mA = data_files_abs['Sham'].iloc[0] #sham condi baseline <1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, p = shapiro(b1_sham_abs_gtr_1mA) #testing for normality\n",
    "print(test, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats.ttest_ind(b1_sham_abs_gtr_1mA, b1_sham_abs_less_1mA, equal_var= False)) #t-test between the >1mA and <1mA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(15,10))\n",
    "fig,ax = plt.subplots(figsize = ((15,10)))\n",
    "data_to_plot = [b1_sham_abs_gtr_1mA, b1_sham_abs_less_1mA]\n",
    "plt.boxplot(data_to_plot, patch_artist=True)\n",
    "labels = [item.get_text() for item in ax.get_xticklabels()]\n",
    "labels[1] = '<1mA'\n",
    "labels[0] = '>1mA'\n",
    "ax.set_xticklabels(labels)\n",
    "ax.spines.right.set_visible(False)\n",
    "ax.spines.top.set_visible(False)\n",
    "ax.spines.left.set_visible(False)\n",
    "ax.spines.bottom.set_visible(False)\n",
    "plt.yticks(size = 18)\n",
    "plt.xticks(size = 18)\n",
    "plt.grid(True, axis = \"y\", color='w', linestyle='-', linewidth=2)\n",
    "plt.gca().patch.set_facecolor('.91')\n",
    "\n",
    "plt.ylim(250,650)\n",
    "plt.rc('xtick', labelsize=23) \n",
    "plt.rc('ytick', labelsize=23) \n",
    "plt.rc('axes', titlesize=30)   \n",
    "plt.rc('axes', labelsize=22)\n",
    "plt.xlabel('Stimulation dose (mA)', fontsize = 26)\n",
    "plt.ylabel('Reaction time (ms)', fontsize = 26)\n",
    "plt.title('BASELINE PERFORMANCE - Sham Block1', fontsize = 30)\n",
    "plt.show()\n",
    "# fig.savefig(r\"/home/friction_15/lab/dissertation/reviewFigures/baselinePerformance.jpg\", format=\"jpg\", dpi = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subjectwise - block rxn time - learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Absolute Reaction time\n",
    "ax = block_rt_abs_mean.plot(yerr = block_rt_abs_er, ylim=[300, 500],figsize = (19,11), rot = 25, capsize = 5, linewidth = 2.3, \n",
    "    marker = 'o', markersize = 12, markerfacecolor = 'white' )\n",
    "\n",
    "ax.legend(loc = \"upper right\", borderpad=1.5, labelspacing=1.5, handlelength=5, prop = {\"size\":12 })\n",
    "# ax.set_frame_on(False)\n",
    "ax.spines.right.set_visible(False)\n",
    "ax.spines.top.set_visible(False)\n",
    "ax.spines.left.set_visible(False)\n",
    "ax.spines.bottom.set_visible(False)\n",
    "plt.yticks(size = 18)\n",
    "plt.xticks(size = 18)\n",
    "plt.grid(True, axis = \"y\", color='w', linestyle='-', linewidth=2)\n",
    "plt.gca().patch.set_facecolor('.91')\n",
    "plt.ylabel(\"RT(ms)\", fontname = \"sans\", size = 26)\n",
    "plt.xlabel(\"Blocks\", fontname = \"sans\", size = 26)\n",
    "# plt.title(\"Stimulation intensity >1mA\", fontname= \"serif\", size = 30)\n",
    "# plt.savefig(r\"/home/friction_15/lab/dissertation/reviewFigures/srtt/Abs.jpg\", format=\"jpg\", dpi = 500)\n",
    "# plt.savefig(r\"/home/friction_15/lab/dissertation/reviewFigures/srttgtr/gtrAbsRT.jpg\", format=\"jpg\", dpi = 500)\n",
    "# plt.savefig(r'E:\\new_figures\\rt_block_21.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalised RT\n",
    "\n",
    "ax = block_mean.plot(yerr = block_err, ylim=[0.8, 1.10],figsize = (19,11), rot = 25, capsize = 5, linewidth = 2.3, \n",
    "    marker = 'o', markersize = 12, markerfacecolor = 'white' ) #for poster linewidth = 4 otherwise 2.3; paper: figsize = (19,11)\n",
    "ax.legend(loc = \"upper right\", borderpad=1.5, labelspacing=1.5, handlelength=5, prop = {\"size\":15})\n",
    "ax.spines.right.set_visible(True)\n",
    "ax.spines.top.set_visible(True)\n",
    "ax.spines.left.set_visible(True)\n",
    "ax.spines.bottom.set_visible(True)\n",
    "plt.yticks(size = 20)\n",
    "plt.xticks(size = 20)\n",
    "plt.grid(True, axis = \"y\", color='grey', linestyle='-', linewidth=0.8)\n",
    "plt.gca().patch.set_facecolor('1') #check from previous cell for paper\n",
    "plt.ylabel(\"Normalised RT\", fontname = \"sans\",size = 30)\n",
    "plt.xlabel(\"Blocks\", fontname = \"sans\", size = 30)\n",
    "# plt.savefig(r\"/home/friction_15/lab/dissertation/reviewFigures/srtt/normPoster.jpg\", format=\"jpg\", dpi = 500)\n",
    "\n",
    "# plt.title(\"Stimulation intensity <1mA\", fontname = \"serif\",size = 30)\n",
    "# plt.savefig(r\"/home/friction_15/lab/dissertation/reviewFigures/srttLess/lessnormRT.jpg\", format=\"jpg\", dpi = 500)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inter subject z- score\n",
    "for key in data_files_full:\n",
    "    mean_block_1 = data_files_full[key].loc[\"Block2\"].mean()\n",
    "    z_score = (data_files_full[key].T - data_files_full[key].T.mean()) / data_files_full[key].T.std()\n",
    "    std_blockwise = data_files_full[key].std(axis = 1)\n",
    "    fig = px.strip(z_score, hover_name = z_score.index.str[-4:-2])\n",
    "    fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normaility test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shapiro wilk test\n",
    "for blocks in data_files_full:\n",
    "    normality_full, p_val = shapiro(data_files_full[blocks])\n",
    "    print(blocks, \"test_stat- \", normality_full, \"p_value- \", p_val )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Blockwise Distribution across tDCS conditions\n",
    "fig1, axis1 = plt.subplots(2,4,figsize=(15, 15))\n",
    "fig2, axis2 = plt.subplots(2,4,figsize=(15, 15))\n",
    "fig3, axis3 = plt.subplots(2,4,figsize=(15, 15))\n",
    "axis = [axis1,axis2,axis3]\n",
    "for ind, blocks in enumerate(data_files_abs):\n",
    "    k = 0\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for index, row in data_files_full[blocks].iterrows():\n",
    "        normality_rt, p = shapiro(row)\n",
    "        print(blocks,index, ': ', 'test_stat - ', normality_rt, 'p-value - ',p)\n",
    "        row.plot.hist(ax = axis[ind][i,j], title = index)\n",
    "        k += 1\n",
    "        j = k%4\n",
    "        if k>3:\n",
    "            i = 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7646d542c936ad5cb0e2a79856d32e94320ebbf9c0d0df29132793802f259745"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
